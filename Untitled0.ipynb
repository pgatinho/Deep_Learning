{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CS2o4QoUp4m-kW-UrLk8K5SUrbk54Zfk",
      "authorship_tag": "ABX9TyPFfvm8XrMQDdy30q0Ty6bF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgatinho/Deep_Learning/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNJ-PLAAdujB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU1MX7HIvl2R"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
        "import albumentations as A\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Activation\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH0NnEGqxBwr"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "import pandas as pd \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt3WxVMVMmLY"
      },
      "source": [
        "test='/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/test'\n",
        "train='/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/train'\n",
        "validation='/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/validation'\n",
        "\n",
        "dados='/content/drive/MyDrive/trabalho 2 deep learning/cell_images/cell_images'\n",
        "#dados='/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/validation'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqAH4qe6I0ag"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "data = tf.keras.preprocessing.image.ImageDataGenerator(rescale= 1/255.0,\n",
        "                                                       validation_split = 0.2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba6vMECOI5GD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f7021c-d3a5-4127-9a59-1676c416d2f6"
      },
      "source": [
        "train_data = data.flow_from_directory(dados,\n",
        "                                      target_size = (200,200),\n",
        "                                      class_mode = \"binary\",\n",
        "                                      batch_size = 16,\n",
        "                                      subset = \"training\")                                           \n",
        "                                           \n",
        "test_data = data.flow_from_directory(dados,\n",
        "                                     target_size = (200,200),\n",
        "                                     class_mode = \"binary\",\n",
        "                                     batch_size = 16,\n",
        "                                     subset = \"validation\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22048 images belonging to 2 classes.\n",
            "Found 5510 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xrGx88XKv0u"
      },
      "source": [
        "#class_labels = list(train_data.class_indices.keys())\n",
        "class_labels=train_data.labels\n",
        "#len(class_labels)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lutD4eHQs1pM"
      },
      "source": [
        "#from sklearn import preprocessing\n",
        "#binary=preprocessing.LabelBinarizer()\n",
        "#class_labels=binary.fit_transform(class_labels)\n",
        "#class_labels.shape\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYmdRIceKUv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2685968b-1204-4ff5-f12d-7c521d75bf7a"
      },
      "source": [
        "image,label = train_data.next()\n",
        "print(image.shape)\n",
        "print(label.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 200, 200, 3)\n",
            "(16,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXMgP6iYKmNQ"
      },
      "source": [
        "#import matplotlib.pyplot as plt\n",
        "#import tensorflow as tf\n",
        "\n",
        "#plt.figure(figsize=(16,16))\n",
        "\n",
        "#for i in range(18):\n",
        "\n",
        " # image,label = train_data.next()\n",
        "\n",
        "  #plt.subplot(6,3,i+1)\n",
        "  #plt.imshow(image[i])\n",
        "  #plt.title(class_labels[tf.argmax(label[i])])\n",
        "  #plt.axis(\"off\")\n",
        "\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ6Na4hgPKbY"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "from keras import models\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3,3), input_shape = (200,200, 3), activation='relu'))\n",
        "model.add(MaxPool2D(2,2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(MaxPool2D(2,2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))                           "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imeNLuSOdzQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9aaa5ec-4443-46ae-e8b9-e83714bb91d7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 198, 198, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 99, 99, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 99, 99, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 97, 97, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 48, 48, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 48, 48, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 73728)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4718656   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,723,809\n",
            "Trainable params: 4,723,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t_03zgkpqtC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f340e03-d8ff-4d81-9b49-8be471d98f2a"
      },
      "source": [
        "len(train_data)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1378"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As8Yis75PO0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c902047-4547-4bfb-e592-a4992ffddddd"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "history=model.fit(train_data, \n",
        "                  epochs = 10,\n",
        "                  steps_per_epoch=len(train_data),\n",
        "                  validation_data = test_data,\n",
        "                  validation_steps=len(test_data)) \n",
        "                  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 259/1378 [====>.........................] - ETA: 37:48 - loss: 0.7178 - accuracy: 0.5555"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3KslbPGwDO3"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikIlpcahwGuH"
      },
      "source": [
        "\n",
        "  # Plot training & validation accuracy values\n",
        "  epoch_range = range(1, epoch+1)\n",
        "  plt.plot(epoch_range,'m', history.history['accuracy'])\n",
        "  plt.plot(epoch_range,'c*' ,history.history['val_accuracy'])\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Plot training & validation loss values\n",
        "  plt.plot(epoch_range,'m' ,history.history['loss'])\n",
        "  plt.plot(epoch_range,'c*' ,history.history['val_loss'])\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxqGSHknDA-a"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "hist = model.fit_generator(steps_per_epoch=100,generator=traindata, validation_data= testdata, validation_steps=10,epochs=100,callbacks=[checkpoint,early])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3JOuAMooH8P"
      },
      "source": [
        "model_evaluation = model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujkMnu-D9hEg"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "\n",
        "for i in range(18):\n",
        "\n",
        "  image,label = train_data.next()\n",
        "\n",
        "  model_pred = model.predict(image)\n",
        "\n",
        "  plt.subplot(6,3,i+1)\n",
        "  plt.imshow(image[i])\n",
        "  plt.title(f\"Prediction : {class_labels[tf.argmax(model_pred[i])]}\\n Original : {class_labels[tf.argmax(label[i])]}\")\n",
        "  plt.subplots_adjust(top = 1.25)\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiIAj9iOZikB"
      },
      "source": [
        "train_labels=os.listdir(train)\n",
        "test_labels=os.listdir(testt)\n",
        "validation_labels=os.listdir(validation)\n",
        "test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "714kKh3DCYvW"
      },
      "source": [
        "import random\n",
        "#taking random 25 random samples from PARASITIZED folder\n",
        "filenames = random.sample(os.listdir('/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/test/Parasitized'),20)\n",
        "plt.figure(figsize=(15, 15)) \n",
        "\n",
        "#Displaying 25 sample\n",
        "for i in range(1, len(filenames)+1):\n",
        "    row = i\n",
        "    image = plt.imread('/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/test/Parasitized/' + filenames[i-1])\n",
        "    res = resize(image, (200, 200))\n",
        "\n",
        "    res.save(f + 'resized.jpg', 'JPEG', quality=90)\n",
        "\n",
        "    imgplot = plt.imshow(res)\n",
        "    plt.subplot(47, 44, row)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(res)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsW3PqWX2pOn"
      },
      "source": [
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "imagem=('/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/test/Parasitized/C101P62ThinF_IMG_20150923_165215_cell_27.png')\n",
        "im = plt.imread(imagem)\n",
        "res = resize(im, (100, 100))\n",
        "imgplot = plt.imshow(res)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vLswTzBsSUe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L74VghXGr_Bl"
      },
      "source": [
        "\n",
        "\n",
        "path = ('/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/test/Parasitized/')\n",
        "\n",
        "#for file in files:\n",
        " # img=Image.open(file)\n",
        "  \n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "\n",
        "dirs =path\n",
        "final_size = 244;\n",
        "\n",
        "#def resize_aspect_fit():\n",
        "for item in dirs:\n",
        "   if os.path.isfile(path+item):\n",
        "     im = Image.open(path+item)\n",
        "     f, e = os.path.splitext(path+item)\n",
        "     size = im.size\n",
        "     ratio = float(final_size) / max(size)\n",
        "     new_image_size = Tuple([int(x*ratio) for x in size])\n",
        "     im = im.resize(new_image_size, Image.ANTIALIAS)\n",
        "     new_im = Image.new(\"RGB\", (final_size, final_size))\n",
        "     new_im.paste(im, ((final_size-new_image_size[0])//2, (final_size-new_image_size[1])//2))\n",
        "     new_im.save(f + 'resized.jpg', 'JPEG', quality=90)\n",
        "resize_aspect_fit()\n",
        "\n",
        "os.listdir(path)\n",
        "\n",
        "\n",
        "\n",
        "    image = plt.imread('/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/test/Parasitized/' + filenames[i-1])\n",
        "    res = resize(image, (200, 200))\n",
        "\n",
        "    res.save(f + 'resized.jpg', 'JPEG', quality=90)\n",
        "\n",
        "    imgplot = plt.imshow(res)\n",
        "    plt.subplot(47, 44, row)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(res)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W61jdfKfHyb5"
      },
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "#taking random 25 random samples from PARASITIZED folder\n",
        "filenames = random.sample(os.listdir('/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/test/Parasitized'),20)\n",
        "plt.figure(figsize=(15, 15)) \n",
        "\n",
        "#Displaying 25 sample\n",
        "\n",
        "for i in range(1, len(filenames)+1):\n",
        "  row=i\n",
        "  im=Image.open()\n",
        "  res=resize(im, (200,200))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YST0xfHviafh"
      },
      "source": [
        "\n",
        "from skimage.transform import resize\n",
        "img=os.path.join( '/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/test/Parasitized/C101P62ThinF_IMG_20150923_165215_cell_27.png')\n",
        "#img = ('/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/test/Parasitized/C101P62ThinF_IMG_20150923_165215_cell_27.png')\n",
        "resize(img, (100, 100)).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RfXJuspjG5B"
      },
      "source": [
        "from skimage import data\n",
        "from skimage.transform import resize\n",
        "image = data.camera()\n",
        "#resize(image, (100, 100)).shape\n",
        "img = mpimg.imread(image)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzc0chD7be9r"
      },
      "source": [
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras import tf.keras.preprocessing.image\n",
        "img_data = np.random.random(size=(100, 100, 3))\n",
        "img = tf.keras.preprocessing.image.array_to_img(img_data)\n",
        "array = tf.keras.preprocessing.image.img_to_array(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Rt40MsZqUK"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "from keras import Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense,Activation,Dropout \n",
        "\n",
        "\n",
        "model=models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(142, 163, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(layers.Dense(2,activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktsLx64AcJKd"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Activation, Dense, MaxPooling2D, Flatten, Dropout\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history=model.fit(train, train_labels,\n",
        "                  validation_data=(validation,validation_labels),\n",
        "                  batch_size=1,\n",
        "                  epochs=60, \n",
        "                  verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRYEMzg5kXJd"
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "for i in train:\n",
        "    try:\n",
        "    \n",
        "        image = cv2.imread(\"/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/train/Parasitized\"+i)\n",
        "        image_array = Image.fromarray(image , 'RGB')\n",
        "        resize_img = image_array.resize((50 , 50))\n",
        "        rotated45 = resize_img.rotate(45)\n",
        "        rotated75 = resize_img.rotate(75)\n",
        "        blur = cv2.blur(np.array(resize_img) ,(10,10))\n",
        "        data.append(np.array(resize_img))\n",
        "        data.append(np.array(rotated45))\n",
        "        data.append(np.array(rotated75))\n",
        "        data.append(np.array(blur))\n",
        "        labels.append(1)\n",
        "        labels.append(1)\n",
        "        labels.append(1)\n",
        "        labels.append(1)\n",
        "        \n",
        "    except AttributeError:\n",
        "        print('2')\n",
        "    \n",
        "for u in train:\n",
        "    try:\n",
        "        \n",
        "        image = cv2.imread(\"/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/train/Uninfected\"+u)\n",
        "        image_array = Image.fromarray(image , 'RGB')\n",
        "        resize_img = image_array.resize((50 , 50))\n",
        "        rotated45 = resize_img.rotate(45)\n",
        "        rotated75 = resize_img.rotate(75)\n",
        "        data.append(np.array(resize_img))\n",
        "        data.append(np.array(rotated45))\n",
        "        data.append(np.array(rotated75))\n",
        "        labels.append(0)\n",
        "        labels.append(0)\n",
        "        labels.append(0)\n",
        "        \n",
        "    except AttributeError:\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rkmxO3LeHqx"
      },
      "source": [
        "filenames = os.listdir(test)\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'Parasitized':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioAUTf2CfLG5"
      },
      "source": [
        "import random\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "sample = random.choice(filenames)\n",
        "image = load_img('/content/drive/MyDrive/trabalho 2 deep learning/cell_images(top).zip (Unzipped Files)/cell_images(top)/test')\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjNkHMB1l1bT"
      },
      "source": [
        "cells = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "np.save('Cells' , cells)\n",
        "np.save('Labels' , labels)\n",
        "print('Cells : {} | labels : {}'.format(cells.shape , labels.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZIo04abb9S_"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlk1tfdIA4Xt"
      },
      "source": [
        "model.compile(optimizer=RMSprop(), loss='mae')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}